{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# from skimage import io\n",
    "from torchvision.datasets import LFWPairs\n",
    "\n",
    "lfw_dataset = LFWPairs(\n",
    "    root='/scratch/sj4020/lfw/',\n",
    "    transform=None,\n",
    "    target_transform=None,\n",
    "    download=True,\n",
    "    split=\"10fold\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 6000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of images: {len(lfw_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: (250, 250)\n",
      "Target name: 1\n"
     ]
    }
   ],
   "source": [
    "image1, image2,target = lfw_dataset[0]\n",
    "print(f\"Image size: {image1.size}\")\n",
    "print(f\"Target name: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of target 1 in LFW Pairs dataset:  3000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "targets = np.asarray(lfw_dataset.targets)\n",
    "num_target_1 = (targets == 1).sum()\n",
    "print(\"Number of target 1 in LFW Pairs dataset: \", num_target_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.4332, 0.3757, 0.3340])\n",
      "Standard Deviation: tensor([0.2711, 0.2446, 0.2346])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Define the transforms\n",
    "transform = transforms.Compose([    transforms.ToTensor()])\n",
    "\n",
    "# Load the dataset\n",
    "lfw_pairs_dataset = ImageFolder('/scratch/sj4020/lfw/', transform=transform)\n",
    "\n",
    "# Calculate the mean and standard deviation\n",
    "loader = torch.utils.data.DataLoader(lfw_pairs_dataset, batch_size=1, shuffle=False)\n",
    "mean = 0.\n",
    "std = 0.\n",
    "for images, _ in loader:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "\n",
    "mean /= len(loader.dataset)\n",
    "std /= len(loader.dataset)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Standard Deviation:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "import augmentations as aug\n",
    "transforms = aug.TrainTransform()\n",
    "class CustomDataset1(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get the first image from the data point and apply the desired transforms\n",
    "        image1 = self.data[index][0]\n",
    "        if self.data[index][2]==1:\n",
    "            image2 = self.data[index][1]\n",
    "            img1 =transforms.transform(image1)\n",
    "            img2 =transforms.transform_prime(image2)\n",
    "\n",
    "            # return the transformed image1 along with the target label\n",
    "            return img1, img2,self.data[index][2]\n",
    "        return None\n",
    "\n",
    "class CustomDataset2(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get the second image from the data point and apply the desired transforms\n",
    "        image2 = self.data[index][1]\n",
    "        if self.data[index][2]==0:\n",
    "            img1 =transforms.transform(image2)\n",
    "            img2 =transforms.transform_prime(image2)\n",
    "        \n",
    "            # return the transformed image2 along with the target label\n",
    "            return img1, img2,self.data[index][2]\n",
    "        return None\n",
    "    \n",
    "class CustomDataset3(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get the first image from the data point and apply the desired transforms\n",
    "        image1 = self.data[index][0]\n",
    "        if self.data[index][2]==0:\n",
    "            img1 =transforms.simple_transform(image1)\n",
    "            img2 =transforms.transform_prime(image1)\n",
    "\n",
    "            # return the transformed image1 along with the target label\n",
    "            return img1, img2,self.data[index][2]\n",
    "        return None\n",
    "\n",
    "# combine the two datasets using ConcatDataset\n",
    "combined_dataset = ConcatDataset([CustomDataset1(lfw_dataset), CustomDataset2(lfw_dataset),CustomDataset3(lfw_dataset)])\n",
    "batch_size=256\n",
    "num_workers=4\n",
    "\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "def custom_collate(batch):\n",
    "    batch = [sample for sample in batch if sample is not None]\n",
    "    return default_collate(batch)\n",
    "# create the dataloader using the combined dataset\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    combined_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=custom_collate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Index: 0\n",
      "Data 1: torch.Size([126, 3, 224, 224])\n",
      "Data 2: torch.Size([126, 3, 224, 224])\n",
      "Target: torch.Size([126])\n",
      "Batch Index: 1\n",
      "Data 1: torch.Size([135, 3, 224, 224])\n",
      "Data 2: torch.Size([135, 3, 224, 224])\n",
      "Target: torch.Size([135])\n",
      "Batch Index: 2\n",
      "Data 1: torch.Size([129, 3, 224, 224])\n",
      "Data 2: torch.Size([129, 3, 224, 224])\n",
      "Target: torch.Size([129])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data1, data2, target) in enumerate(dataloader):\n",
    "    print('Batch Index:', batch_idx)\n",
    "    print('Data 1:', data1.shape)\n",
    "    print('Data 2:', data2.shape)\n",
    "    print('Target:', target.shape)\n",
    "    \n",
    "    # stop after printing a few batches\n",
    "    if batch_idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_bias_and_norm(p):\n",
    "    return p.ndim == 1\n",
    "\n",
    "\n",
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.arch = 'resnet50'\n",
    "        self.mlp = '8192-8192-8192'\n",
    "        self.sim_coeff=25\n",
    "        self.std_coeff=25\n",
    "        self.cov_coeff=1\n",
    "        self.batch_size = 512\n",
    "        self.log_freq_time=50\n",
    "        self.base_lr=0.2\n",
    "        self.exp_dir=Path(\"./exp\")\n",
    "        self.epochs=30\n",
    "        self.wd=1e-6\n",
    "\n",
    "args = Args()\n",
    "# namespace = argparse.Namespace(**vars(args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resnet\n",
    "from torch import nn\n",
    "class VICReg(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.num_features = int(args.mlp.split(\"-\")[-1])\n",
    "        self.backbone, self.embedding = resnet.__dict__[args.arch](zero_init_residual=True)\n",
    "        self.projector = Projector(args, self.embedding)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.projector(self.backbone(x))\n",
    "        y = self.projector(self.backbone(y))\n",
    "\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "        # x = torch.cat(x, dim=0)\n",
    "        # y = torch.cat(y, dim=0)\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "\n",
    "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
    "\n",
    "        cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
    "        cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
    "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(\n",
    "            self.num_features\n",
    "        ) + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
    "\n",
    "        loss = (\n",
    "            self.args.sim_coeff * repr_loss\n",
    "            + self.args.std_coeff * std_loss\n",
    "            + self.args.cov_coeff * cov_loss\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def Projector(args, embedding):\n",
    "    mlp_spec = f\"{embedding}-{args.mlp}\"\n",
    "    layers = []\n",
    "    f = list(map(int, mlp_spec.split(\"-\")))\n",
    "    for i in range(len(f) - 2):\n",
    "        layers.append(nn.Linear(f[i], f[i + 1]))\n",
    "        layers.append(nn.BatchNorm1d(f[i + 1]))\n",
    "        layers.append(nn.ReLU(True))\n",
    "    layers.append(nn.Linear(f[-2], f[-1], bias=False))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VICReg(args).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt=torch.load(\"exp/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt=torch.load(\"exp/resnet50_fullckpt.pth\")\n",
    "state_dict = {k.replace('module.', ''): v for k, v in ckpt[\"model\"].items()}\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(ckpt[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(args, optimizer, loader, step):\n",
    "    max_steps = args.epochs * len(loader)\n",
    "    warmup_steps = 10 * len(loader)\n",
    "    base_lr = args.base_lr * args.batch_size / 256\n",
    "    if step < warmup_steps:\n",
    "        lr = base_lr * step / warmup_steps\n",
    "    else:\n",
    "        step -= warmup_steps\n",
    "        max_steps -= warmup_steps\n",
    "        q = 0.5 * (1 + math.cos(math.pi * step / max_steps))\n",
    "        end_lr = base_lr * 0.001\n",
    "        lr = base_lr * q + end_lr * (1 - q)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "class LARS(optim.Optimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        params,\n",
    "        lr,\n",
    "        weight_decay=0,\n",
    "        momentum=0.9,\n",
    "        eta=0.001,\n",
    "        weight_decay_filter=None,\n",
    "        lars_adaptation_filter=None,\n",
    "    ):\n",
    "        defaults = dict(\n",
    "            lr=lr,\n",
    "            weight_decay=weight_decay,\n",
    "            momentum=momentum,\n",
    "            eta=eta,\n",
    "            weight_decay_filter=weight_decay_filter,\n",
    "            lars_adaptation_filter=lars_adaptation_filter,\n",
    "        )\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for g in self.param_groups:\n",
    "            for p in g[\"params\"]:\n",
    "                dp = p.grad\n",
    "\n",
    "                if dp is None:\n",
    "                    continue\n",
    "\n",
    "                if g[\"weight_decay_filter\"] is None or not g[\"weight_decay_filter\"](p):\n",
    "                    dp = dp.add(p, alpha=g[\"weight_decay\"])\n",
    "\n",
    "                if g[\"lars_adaptation_filter\"] is None or not g[\n",
    "                    \"lars_adaptation_filter\"\n",
    "                ](p):\n",
    "                    param_norm = torch.norm(p)\n",
    "                    update_norm = torch.norm(dp)\n",
    "                    one = torch.ones_like(param_norm)\n",
    "                    q = torch.where(\n",
    "                        param_norm > 0.0,\n",
    "                        torch.where(\n",
    "                            update_norm > 0, (g[\"eta\"] * param_norm / update_norm), one\n",
    "                        ),\n",
    "                        one,\n",
    "                    )\n",
    "                    dp = dp.mul(q)\n",
    "\n",
    "                param_state = self.state[p]\n",
    "                if \"mu\" not in param_state:\n",
    "                    param_state[\"mu\"] = torch.zeros_like(p)\n",
    "                mu = param_state[\"mu\"]\n",
    "                mu.mul_(g[\"momentum\"]).add_(dp)\n",
    "\n",
    "                p.add_(mu, alpha=-g[\"lr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"epoch\": 0, \"step\": 56, \"loss\": 22.21867561340332, \"time\": 51, \"lr\": 0.03154929577464789}\n",
      "{\"epoch\": 1, \"step\": 99, \"loss\": 21.072938919067383, \"time\": 102, \"lr\": 0.05577464788732395}\n",
      "{\"epoch\": 1, \"step\": 131, \"loss\": 20.112300872802734, \"time\": 155, \"lr\": 0.07380281690140846}\n",
      "{\"epoch\": 2, \"step\": 161, \"loss\": 20.30962562561035, \"time\": 205, \"lr\": 0.09070422535211269}\n",
      "{\"epoch\": 2, \"step\": 190, \"loss\": 19.579139709472656, \"time\": 255, \"lr\": 0.10704225352112676}\n",
      "{\"epoch\": 3, \"step\": 234, \"loss\": 19.24996566772461, \"time\": 306, \"lr\": 0.13183098591549297}\n",
      "{\"epoch\": 4, \"step\": 289, \"loss\": 18.1663875579834, \"time\": 356, \"lr\": 0.1628169014084507}\n",
      "{\"epoch\": 4, \"step\": 348, \"loss\": 18.557510375976562, \"time\": 407, \"lr\": 0.19605633802816905}\n",
      "{\"epoch\": 5, \"step\": 404, \"loss\": 18.93300437927246, \"time\": 459, \"lr\": 0.22760563380281693}\n",
      "{\"epoch\": 6, \"step\": 459, \"loss\": 17.464313507080078, \"time\": 510, \"lr\": 0.25859154929577466}\n",
      "{\"epoch\": 7, \"step\": 516, \"loss\": 17.816692352294922, \"time\": 560, \"lr\": 0.2907042253521127}\n",
      "{\"epoch\": 8, \"step\": 570, \"loss\": 17.102632522583008, \"time\": 611, \"lr\": 0.3211267605633803}\n",
      "{\"epoch\": 8, \"step\": 616, \"loss\": 16.700380325317383, \"time\": 661, \"lr\": 0.3470422535211268}\n",
      "{\"epoch\": 9, \"step\": 647, \"loss\": 16.836013793945312, \"time\": 712, \"lr\": 0.36450704225352115}\n",
      "{\"epoch\": 9, \"step\": 708, \"loss\": 17.239437103271484, \"time\": 763, \"lr\": 0.3988732394366197}\n",
      "{\"epoch\": 10, \"step\": 746, \"loss\": 16.82490348815918, \"time\": 815, \"lr\": 0.3993666205686445}\n",
      "{\"epoch\": 11, \"step\": 797, \"loss\": 16.684038162231445, \"time\": 866, \"lr\": 0.39631034436731893}\n",
      "{\"epoch\": 12, \"step\": 852, \"loss\": 16.57954216003418, \"time\": 919, \"lr\": 0.3902210919557717}\n",
      "{\"epoch\": 12, \"step\": 908, \"loss\": 16.442359924316406, \"time\": 969, \"lr\": 0.38113472944492344}\n",
      "{\"epoch\": 13, \"step\": 949, \"loss\": 16.610021591186523, \"time\": 1019, \"lr\": 0.3727138645104758}\n",
      "{\"epoch\": 13, \"step\": 984, \"loss\": 16.13412094116211, \"time\": 1072, \"lr\": 0.3644000447174657}\n",
      "{\"epoch\": 14, \"step\": 1015, \"loss\": 16.146820068359375, \"time\": 1124, \"lr\": 0.356212874843911}\n",
      "{\"epoch\": 15, \"step\": 1071, \"loss\": 16.026851654052734, \"time\": 1174, \"lr\": 0.3395921456080539}\n",
      "{\"epoch\": 15, \"step\": 1109, \"loss\": 15.984299659729004, \"time\": 1227, \"lr\": 0.3270798712717541}\n",
      "{\"epoch\": 16, \"step\": 1152, \"loss\": 14.923055648803711, \"time\": 1277, \"lr\": 0.3118452921866916}\n",
      "{\"epoch\": 17, \"step\": 1208, \"loss\": 15.721822738647461, \"time\": 1327, \"lr\": 0.2905132237880793}\n",
      "{\"epoch\": 17, \"step\": 1267, \"loss\": 16.084381103515625, \"time\": 1378, \"lr\": 0.266547263262107}\n",
      "{\"epoch\": 18, \"step\": 1324, \"loss\": 16.080093383789062, \"time\": 1429, \"lr\": 0.24231707535666577}\n",
      "{\"epoch\": 19, \"step\": 1379, \"loss\": 14.827082633972168, \"time\": 1479, \"lr\": 0.2182986069212053}\n",
      "{\"epoch\": 20, \"step\": 1433, \"loss\": 14.492941856384277, \"time\": 1529, \"lr\": 0.19445433252204322}\n",
      "{\"epoch\": 21, \"step\": 1491, \"loss\": 14.399559020996094, \"time\": 1581, \"lr\": 0.16894439388496185}\n",
      "{\"epoch\": 21, \"step\": 1551, \"loss\": 13.783442497253418, \"time\": 1632, \"lr\": 0.1431006372477968}\n",
      "{\"epoch\": 22, \"step\": 1586, \"loss\": 14.217893600463867, \"time\": 1683, \"lr\": 0.12846054464354295}\n",
      "{\"epoch\": 23, \"step\": 1642, \"loss\": 15.488651275634766, \"time\": 1734, \"lr\": 0.10596620553636016}\n",
      "{\"epoch\": 23, \"step\": 1686, \"loss\": 15.355661392211914, \"time\": 1785, \"lr\": 0.08928896915931456}\n",
      "{\"epoch\": 24, \"step\": 1736, \"loss\": 15.15665054321289, \"time\": 1836, \"lr\": 0.07162060048039434}\n",
      "{\"epoch\": 25, \"step\": 1791, \"loss\": 14.927734375, \"time\": 1888, \"lr\": 0.05400855532562546}\n",
      "{\"epoch\": 26, \"step\": 1846, \"loss\": 14.364903450012207, \"time\": 1939, \"lr\": 0.03855840452388552}\n",
      "{\"epoch\": 26, \"step\": 1905, \"loss\": 14.272953033447266, \"time\": 1989, \"lr\": 0.024647506333500064}\n",
      "{\"epoch\": 27, \"step\": 1961, \"loss\": 14.522141456604004, \"time\": 2040, \"lr\": 0.014203735879167139}\n",
      "{\"epoch\": 28, \"step\": 2016, \"loss\": 13.709627151489258, \"time\": 2091, \"lr\": 0.0067211320687467066}\n",
      "{\"epoch\": 29, \"step\": 2071, \"loss\": 14.522216796875, \"time\": 2142, \"lr\": 0.0020997139654835265}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = LARS(\n",
    "    model.parameters(),\n",
    "    lr=0,\n",
    "    weight_decay=args.wd,\n",
    "    weight_decay_filter=exclude_bias_and_norm,\n",
    "    lars_adaptation_filter=exclude_bias_and_norm,\n",
    ")\n",
    "args.exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "stats_file = open(args.exp_dir / \"stats.txt\", \"a\", buffering=1)\n",
    "# print(\" \".join(sys.argv))\n",
    "# print(\" \".join(sys.argv), file=stats_file)\n",
    "\n",
    "# if (args.exp_dir / \"model.pth\").is_file():\n",
    "#     if args.rank == 0:\n",
    "#         print(\"resuming from checkpoint\")\n",
    "#     ckpt = torch.load(args.exp_dir / \"model.pth\", map_location=\"cpu\")\n",
    "#     start_epoch = ckpt[\"epoch\"]\n",
    "#     model.load_state_dict(ckpt[\"model\"])\n",
    "#     optimizer.load_state_dict(ckpt[\"optimizer\"])\n",
    "# else:\n",
    "start_epoch = 0\n",
    "\n",
    "start_time = last_logging = time.time()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(start_epoch, args.epochs):\n",
    "\n",
    "\n",
    "    for step, (x, y, _) in enumerate(dataloader, start=epoch * len(dataloader)):\n",
    "        x = x.cuda(non_blocking=True)\n",
    "        y = y.cuda(non_blocking=True)\n",
    "\n",
    "        lr = adjust_learning_rate(args, optimizer, dataloader, step)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = model.forward(x, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        current_time = time.time()\n",
    "        if current_time - last_logging > args.log_freq_time:\n",
    "            stats = dict(\n",
    "                epoch=epoch,\n",
    "                step=step,\n",
    "                loss=loss.item(),\n",
    "                time=int(current_time - start_time),\n",
    "                lr=lr,\n",
    "            )\n",
    "            print(json.dumps(stats))\n",
    "            print(json.dumps(stats), file=stats_file)\n",
    "            last_logging = current_time\n",
    "    state = dict(\n",
    "        epoch=epoch + 1,\n",
    "        model=model.state_dict(),\n",
    "        optimizer=optimizer.state_dict(),\n",
    "    )\n",
    "    torch.save(state, args.exp_dir / \"model.pth\")\n",
    "\n",
    "torch.save(model.backbone.state_dict(), args.exp_dir / \"resnet_backbone.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VICReg(\n",
       "  (backbone): ResNet(\n",
       "    (padding): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (last_activation): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (projector): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "    (1): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Linear(in_features=8192, out_features=8192, bias=True)\n",
       "    (4): BatchNorm1d(8192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=8192, out_features=8192, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1,y,target=lfw_dataset[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2,y,target=lfw_dataset[502]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transforms.simple_transform(x1).cuda()\n",
    "y = transforms.simple_transform(x2).cuda()\n",
    "x=torch.stack([x], dim=0)\n",
    "y=torch.stack([y], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_x = model.projector(model.backbone(x))\n",
    "embed_y = model.projector(model.backbone(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5709, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " F.mse_loss(embed_x, embed_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
